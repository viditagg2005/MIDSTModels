{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "# Membership Inference over Diffusion-models-based Synthetic Tabular Data (MIDST) Challenge @ SaTML 2025.\n",
    "\n",
    "## White Box Multi Table Competition\n",
    "Welcome to the MIDST challenge!\n",
    "\n",
    "The MIDST challenge is a multi-track competition aiming to quantitatively evaluate the privacy of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs).\n",
    "\n",
    "This competition focuses on White Box MIA on tabular diffusion models trained on a multi table dataset (Berka). There are 8 tables in total which are related as follows:\n",
    "\n",
    "![image](https://github.com/user-attachments/assets/cae8fc1a-52e4-49d3-bd3b-98d56488b226)\n",
    "\n",
    "In particular, MIA will be explored over a state-of the art method Multi-relational Tabular Diffusion Model [ClavaDDPM](https://arxiv.org/abs/2405.17724). A collection of ClavaDDPM models will be trained on random subsets of the transaction dataset. Given the synthesis algorithm, model checkpoints, and output for all the tables in the Berka dataset, you are expected to perform MIA on challenge points selected from the Transaction table. You can use the other tables as auxiliary information in your attack development, or ignore them. The `final` set includes 20 models, each with its own set of challenge points (ie train and holdout data), to evaluate solutions on. To facilitate designing an attack, 30 `train` models are provided with comprehensive information about the model, training data and output synthetic data. Additionally, 20 `dev` models are provided to assist in evaluating the effectiveness of attacks prior to making a final submission to the `final` set. A high level summary of the competition is below:\n",
    "![wbox_diagram_final](https://github.com/user-attachments/assets/2ebb5eed-a6e3-433a-8769-4310b7fbc822)\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to the white box mutli table challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Package Imports and Evironment Setup\n",
    "\n",
    "Ensure that you have installed the proper dependenices to run the notebook. The environment installation instructions are available [here](https://github.com/VectorInstitute/MIDSTModels/tree/main/starter_kits). Now that we have verfied we have the proper packages installed, lets import them and define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from typing import Callable, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from data import get_challenge_points\n",
    "from metrics import get_tpr_at_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "CLAVADDPM_DATA_DIR = \"clavaddpm_white_box\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Data\n",
    "\n",
    "Next, lets download and extract the data for the competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "!gdown 1OZQbNt7d_ZsSKu1uTW5I0Gh1xhW2uwM7\n",
    "!unzip -qq -o clavaddpm_white_box.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note\n",
    "If there is an issue with the download (ie throttled for the large file, or downloading too many files with gdown) you can instead simply download the zip manually from this [link](https://drive.google.com/file/d/1OZQbNt7d_ZsSKu1uTW5I0Gh1xhW2uwM7/view?usp=drive_link) and extract it in the same directory this notebook exists; it would be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcENY2HGV2Tx",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Contents\n",
    "The archives extracted under the `clavaddpm_white_box` contain 3 subdirectories:\n",
    "\n",
    "- `train`: Comprehensive information (ie model weights+architecture, training data, output synthetic data etc.) about the set of shadow models. Use these to develop your attacks without having to train your own models.\n",
    "- `dev`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions during the competition and update the live scoreboard in CodaBench.\n",
    "- `final`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions when the competition closes and to determine the final ranking.\n",
    "\n",
    "The contents of the `train`, `dev` and `final` subdirectory of `clavaddpm_white_box` contain the following files: \n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Model - Stage</th>\n",
    "      <th>File Name</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <!-- White-Box Models - Train -->\n",
    "    <tr>\n",
    "      <td rowspan=\"36\"><strong>White-Box Models - Train</strong></td>\n",
    "      <!-- Train data with IDs -->\n",
    "      <td>account.csv</td>\n",
    "      <td>Account samples used to train the model</td>\n",
    "    </tr>\n",
    "    <!-- Remaining Train data files -->\n",
    "    <tr>\n",
    "      <td>card.csv</td>\n",
    "      <td>Account samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client.csv</td>\n",
    "      <td>Client samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp.csv</td>\n",
    "      <td>Disposition samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district.csv</td>\n",
    "      <td>District samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan.csv</td>\n",
    "      <td>Loan samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order.csv</td>\n",
    "      <td>Order samples used to train the model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans.csv</td>\n",
    "      <td>Transaction samples used to train the model</td>\n",
    "    </tr>\n",
    "    <!-- Data domain files -->\n",
    "    <tr>\n",
    "      <td>account_domain.json</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_domain.json</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_domain.json</td>\n",
    "      <td>Client data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_domain.json</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column\n",
    "    <tr>\n",
    "      <td>district_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_domain.json</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_domain.json</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_domain.json</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Challenge data and labels -->\n",
    "    <tr>\n",
    "      <td>challenge_with_id.csv</td>\n",
    "      <td>Challenge points sampled from transaction train data and holdout data</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>challenge_label.csv</td>\n",
    "      <td>The labels for the set of challenge points</td>\n",
    "    </tr>\n",
    "    <!-- Label encoders -->\n",
    "    <tr>\n",
    "      <td>account_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in client data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in district data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in loan data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in transaction data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/cluster_ckpt.pkl</td>\n",
    "      <td>Pickled cluster checkpoint used in ClavaDDPM relation-aware clustering</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/models/*</td>\n",
    "      <td>The trained model checkpoints for all the tables used in training</td>\n",
    "    </tr>\n",
    "    <!-- Synthetic data -->\n",
    "    <tr>\n",
    "      <td>workspace/train_1/account/_final/account_synthetic.csv</td>\n",
    "      <td>Synthetic account data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/card/_final/card_synthetic.csv</td>\n",
    "      <td>Synthetic credit card data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/client/_final/client_synthetic.csv</td>\n",
    "      <td>Synthetic client data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/disp/_final/disp_synthetic.csv</td>\n",
    "      <td>Synthetic disposition data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/district/_final/district_synthetic.csv</td>\n",
    "      <td>Synthetic district data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/loan/_final/loan_synthetic.csv</td>\n",
    "      <td>Synthetic loan data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/order/_final/order_synthetic.csv</td>\n",
    "      <td>Synthetic order data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/trans/_final/trans_synthetic.csv</td>\n",
    "      <td>Synthetic order data generated using the corresponding trained model</td>\n",
    "    </tr>\n",
    "    <!-- White-Box Models - Dev -->\n",
    "    <tr>\n",
    "      <td rowspan=\"27\"><strong>White-Box Models - Dev</strong></td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "      <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_domain.json</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_domain.json</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_domain.json</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Challenge data -->\n",
    "    <tr>\n",
    "      <td>challenge_with_id.csv</td>\n",
    "      <td>Challenge points sampled from transaction train data and holdout data</td>\n",
    "    </tr>\n",
    "    <!-- Model checkpoints and other artifacts -->\n",
    "    <tr>\n",
    "      <td>account_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in credit card data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in client data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in loan data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/cluster_ckpt.pkl</td>\n",
    "      <td>Pickled cluster checkpoint used in ClavaDDPM relation-aware clustering</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/models/*</td>\n",
    "      <td>The trained model checkpoints for all the tables used in training</td>\n",
    "    </tr>\n",
    "    <!-- Synthetic data -->\n",
    "    <tr>\n",
    "      <td>workspace/train_1/account/_final/account_synthetic.csv</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/card/_final/card_synthetic.csv</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/client/_final/client_synthetic.csv</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/disp/_final/disp_synthetic.csv</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/district/_final/district_synthetic.csv</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/loan/_final/loan_synthetic.csv</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/order/_final/order_synthetic.csv</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/trans/_final/trans_synthetic.csv</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- White-Box Models - Eval -->\n",
    "    <tr>\n",
    "      <td rowspan=\"27\"><strong>White-Box Models - Final</strong></td>\n",
    "      <!-- Data domain files -->\n",
    "      <td>account_domain.json</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Remaining Eval data files -->\n",
    "    <tr>\n",
    "      <td>card_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_domain.json</td>\n",
    "      <td>Credit card data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_domain.json</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_domain.json</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_domain.json</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_domain.json</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_domain.json</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <!-- Challenge data -->\n",
    "    <tr>\n",
    "      <td>challenge_with_id.csv</td>\n",
    "      <td>Challenge points sampled from transaction train data and holdout data</td>\n",
    "    </tr>\n",
    "    <!-- Model checkpoints and other artifacts -->\n",
    "    <tr>\n",
    "      <td>account_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in account data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in credit card data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>client_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in client data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>disp_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in disposition data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>district_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in district data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>loan_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in loan data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>order_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in order data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>trans_label_encoders.pkl</td>\n",
    "      <td>Pickled label encoders used in transaction data preprocessing</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/cluster_ckpt.pkl</td>\n",
    "      <td>Pickled cluster checkpoint used in ClavaDDPM relation-aware clustering</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/models/*</td>\n",
    "      <td>The trained model checkpoints for all the tables used in training</td>\n",
    "    </tr>\n",
    "    <!-- Synthetic data -->\n",
    "    <tr>\n",
    "      <td>workspace/train_1/account/_final/account_synthetic.csv</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/card/_final/card_synthetic.csv</td>\n",
    "      <td>Account data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/client/_final/client_synthetic.csv</td>\n",
    "      <td>Client data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/disp/_final/disp_synthetic.csv</td>\n",
    "      <td>Disposition data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/district/_final/district_synthetic.csv</td>\n",
    "      <td>District data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/loan/_final/loan_synthetic.csv</td>\n",
    "      <td>Loan data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/order/_final/order_synthetic.csv</td>\n",
    "      <td>Order data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>workspace/train_1/trans/_final/trans_synthetic.csv</td>\n",
    "      <td>Transaction data domain file indicating the domain information for each column</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJRVZ-r9V2Tx"
   },
   "source": [
    "## Task\n",
    "\n",
    "Your task as a competitor is to produce, for each model in `dev` and `final`, a CSV file listing your confidence scores (values between 0 and 1) for the membership of the challenge examples. You must save these scores in a `prediction.csv` file and place it in the same folder as the corresponding model. A submission to the challenge is an an archive containing just these `prediction.csv` files.\n",
    "\n",
    "**You must submit predictions for both `dev` and `final` when you submit to CodaBench.**\n",
    "\n",
    "In the following, we will show you how to compute predictions from a basic membership inference attack and package them as a submission archive. To start, let's create a baseline attack model `clavaddpm_attack_model` based on it's respective shadow models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zBNChV7ZV2Ty"
   },
   "outputs": [],
   "source": [
    "def get_attack_model(base_train_path: Path) -> Callable[[Any], float]:\n",
    "    return lambda x : random.uniform(0, 1)\n",
    "\n",
    "base_clavaddpm_train_path = os.path.join(CLAVADDPM_DATA_DIR, \"train\")\n",
    "clavaddpm_attack_model = get_attack_model(base_clavaddpm_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the attack model, we can obtain predictions for each point in the challenge point set for train, dev and final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ar9drA4LV2Ty"
   },
   "outputs": [],
   "source": [
    "phases = [\"train\", \"dev\", \"final\"]\n",
    "\n",
    "for base_dir, attack_model in zip([CLAVADDPM_DATA_DIR], [clavaddpm_attack_model]):\n",
    "    for phase in phases:\n",
    "        root = os.path.join(base_dir, phase)\n",
    "        model_folders = [item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item))]\n",
    "        for model_folder in sorted(model_folders, key=lambda d: int(d.split('_')[1])):\n",
    "            path = os.path.join(root, model_folder)\n",
    "    \n",
    "            challenge_points = get_challenge_points(path)\n",
    "    \n",
    "            predictions = torch.Tensor([attack_model(cp) for cp in challenge_points])\n",
    "           \n",
    "            assert torch.all((0 <= predictions) & (predictions <= 1))\n",
    "            with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "    \n",
    "                # Write each value in a separate row\n",
    "                for value in list(predictions.numpy().squeeze()):\n",
    "                    writer.writerow([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhGsrlPV2Ty"
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth.\n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-UN3zfuPV2Ty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clavaddpm Train Attack TPR at FPR==10%: 0.10333333333333333\n",
      "Final Train Attack TPR at FPR==10%: 0.10333333333333333\n"
     ]
    }
   ],
   "source": [
    "tpr_at_fpr_list = []\n",
    "for base_dir in [CLAVADDPM_DATA_DIR]:\n",
    "    predictions = []\n",
    "    solutions  = []\n",
    "    root = os.path.join(base_dir, \"train\")\n",
    "    model_folders = [item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item))]\n",
    "    for model_folder in sorted(model_folders, key=lambda d: int(d.split('_')[1])):\n",
    "        path = os.path.join(root, model_folder)\n",
    "        predictions.append(np.loadtxt(os.path.join(path, \"prediction.csv\")))\n",
    "        solutions.append(np.loadtxt(os.path.join(path, \"challenge_label.csv\"), skiprows=1))\n",
    "    \n",
    "    predictions = np.concatenate(predictions)\n",
    "    solutions = np.concatenate(solutions)\n",
    "    \n",
    "    tpr_at_fpr = get_tpr_at_fpr(solutions, predictions)\n",
    "    tpr_at_fpr_list.append(tpr_at_fpr)\n",
    "    \n",
    "    print(f\"{base_dir.split('_')[0]} Train Attack TPR at FPR==10%: {tpr_at_fpr}\")\n",
    "\n",
    "final_tpr_at_fpr = max(tpr_at_fpr_list)\n",
    "print(f\"Final Train Attack TPR at FPR==10%: {final_tpr_at_fpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9LZ-EhfV2Ty"
   },
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaBench. Importantly, we create a single zip file for dev and final. The structure of the submission is as follows:\n",
    "```\n",
    "└── root_folder\n",
    "    ├── clavaddpm_white_box\n",
    "       ├── dev\n",
    "       │   └── clavaddpm_#\n",
    "       │       └── prediction.csv\n",
    "       └── final\n",
    "           └── clavaddpm_#\n",
    "                └── prediction.csv\n",
    "```\n",
    "\n",
    "**Note:** The `root_folder` can have any name but it is important all of the subdirectories follow the above structure and naming conventions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ats5N4AoV2Tz"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(f\"white_box_multi_table_submission.zip\", 'w') as zipf:\n",
    "    for phase in [\"dev\", \"final\"]:\n",
    "        for base_dir in [CLAVADDPM_DATA_DIR]:\n",
    "            root = os.path.join(base_dir, phase)\n",
    "            model_folders = [item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item))]\n",
    "            for model_folder in sorted(model_folders, key=lambda d: int(d.split('_')[1])):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                if not os.path.isdir(path): \n",
    "                    continue\n",
    "\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    arcname = os.path.join(\n",
    "                        CLAVADDPM_DATA_DIR,\n",
    "                        phase,  \n",
    "                        model_folder,  \n",
    "                        os.path.basename(file)\n",
    "                    )\n",
    "                    zipf.write(file, arcname=arcname)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated white_box_multi_table_submission.zip can be directly submitted to the dev phase in the CodaBench UI. Although this submission contains your predictions for both the dev and final set, you will only receive feedback on your predictions for the dev phase. The predictions for the final phase will be evaluated once the competiton ends using the most recent submission to the dev phase."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c823568a0650a753a55947c22141ec594c2fc02bd68b5a71e505ecc57f17796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
